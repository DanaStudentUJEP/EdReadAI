import os
import io
import json
import re
import requests
import streamlit as st
from dataclasses import dataclass
from typing import Dict, List, Tuple

from docx import Document
from docx.shared import Cm, Pt
from docx.enum.text import WD_ALIGN_PARAGRAPH


# =========================
# OpenAI
# =========================
OPENAI_CHAT_URL = "https://api.openai.com/v1/chat/completions"


def get_openai_key() -> str:
    if hasattr(st, "secrets") and "OPENAI_API_KEY" in st.secrets:
        return str(st.secrets["OPENAI_API_KEY"]).strip()
    return (os.getenv("OPENAI_API_KEY") or "").strip()


def get_openai_model() -> str:
    if hasattr(st, "secrets") and "OPENAI_MODEL" in st.secrets:
        return str(st.secrets["OPENAI_MODEL"]).strip()
    return (os.getenv("OPENAI_MODEL") or "gpt-4o-mini").strip()


def call_openai_chat(system_prompt: str, user_prompt: str, temperature: float = 0.2, max_tokens: int = 2200) -> str:
    api_key = get_openai_key()
    if not api_key:
        raise RuntimeError("Chyb√≠ OPENAI_API_KEY (Streamlit Cloud ‚Üí Settings ‚Üí Secrets).")

    payload = {
        "model": get_openai_model(),
        "temperature": float(temperature),
        "max_tokens": int(max_tokens),
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
    }
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    r = requests.post(OPENAI_CHAT_URL, headers=headers, json=payload, timeout=90)

    if r.status_code != 200:
        raise RuntimeError(f"OpenAI API chyba ({r.status_code}): {r.text}")

    data = r.json()
    return data["choices"][0]["message"]["content"]


# =========================
# DOCX helpers
# =========================
def set_doc_defaults(doc: Document) -> None:
    style = doc.styles["Normal"]
    style.font.name = "Calibri"
    style.font.size = Pt(11)


def add_h1(doc: Document, text: str) -> None:
    p = doc.add_paragraph()
    r = p.add_run(text)
    r.bold = True
    r.font.size = Pt(16)


def add_h2(doc: Document, text: str) -> None:
    p = doc.add_paragraph()
    r = p.add_run(text)
    r.bold = True
    r.font.size = Pt(13)


def add_spacer(doc: Document, cm: float = 0.2) -> None:
    p = doc.add_paragraph("")
    p.paragraph_format.space_after = Pt(int(cm * 28.35))


def doc_to_bytes(doc: Document) -> bytes:
    bio = io.BytesIO()
    doc.save(bio)
    return bio.getvalue()


# =========================
# AI ‚Äì struktura z vlastn√≠ho textu
# =========================
@dataclass
class GeneratedStructure:
    simpl: str
    lmp: str
    drama_intro: str
    drama_scene: List[Tuple[str, str]]
    glossary: Dict[str, str]
    questions_A: List[str]
    questions_B: List[str]
    questions_C: List[str]


def ai_generate_structure(full_text: str, grade: int, title: str) -> GeneratedStructure:
    """
    Z jednoho vstupn√≠ho textu vygeneruje:
    - zjednodu≈°enou verzi
    - LMP/SPU verzi
    - dramatizaci (intro + 3‚Äì6 replik)
    - slovn√≠ƒçek pojm≈Ø
    - ot√°zky A/B/C (ƒå≈†I / RVP ZV styl)
    V≈°e v jednom JSONu.
    """
    if not get_openai_key():
        # fallback bez AI ‚Äì v≈°echno stejn√©, bez dramatizace a slovn√≠ƒçku
        return GeneratedStructure(
            simpl=full_text,
            lmp=full_text,
            drama_intro="(Dramatizace nen√≠ k dispozici ‚Äì chyb√≠ OPENAI_API_KEY.)",
            drama_scene=[],
            glossary={},
            questions_A=["(Ot√°zky A nejsou k dispozici ‚Äì chyb√≠ OPENAI_API_KEY.)"],
            questions_B=["(Ot√°zky B nejsou k dispozici ‚Äì chyb√≠ OPENAI_API_KEY.)"],
            questions_C=["(Ot√°zky C nejsou k dispozici ‚Äì chyb√≠ OPENAI_API_KEY.)"],
        )

    system = (
        "Jsi odborn√≠k na ƒçesk√Ω jazyk, ƒçten√°≈ôskou gramotnost a RVP ZV. "
        "Um√≠≈° tvo≈ôit pracovn√≠ listy ve stylu ƒå≈†I (ƒçten√≠ s porozumƒõn√≠m). "
        "V√Ωstup mus√≠ b√Ωt validn√≠ JSON, ≈æ√°dn√Ω koment√°≈ô nav√≠c."
    )

    user = f"""
M√°≈° vytvo≈ôit pracovn√≠ list pro ≈æ√°ky {grade}. roƒçn√≠ku Z≈†.
N√°zev √∫lohy: {title}

Vstupn√≠ text (pln√° verze):
\"\"\"{full_text}\"\"\"

√öKOL:
1) Vytvo≈ô ZJEDNODU≈†ENOU verzi textu (pro bƒõ≈æn√© ≈æ√°ky).
2) Vytvo≈ô LMP/SPU verzi (velmi kr√°tk√© vƒõty, maxim√°ln√≠ srozumitelnost).
3) Vytvo≈ô kr√°tkou DRAMATIZACI:
   - 1‚Äì2 vƒõty ‚Äûdrama_intro‚Äú (co se bude hr√°t, proƒç).
   - 3‚Äì6 replik ve form√°tu: [ ["Role", "replika"], ... ]
   - Dramatizace m√° ≈æ√°k≈Øm pomoci pochopit, o ƒçem text bude (varianta C ‚Äì vymysli ji podle textu).
4) Vytvo≈ô SLOVN√çƒåEK pojm≈Ø:
   - vyber 6‚Äì14 slov z textu, kter√° mohou b√Ωt pro ≈æ√°ky obt√≠≈æn√°,
   - ke ka≈æd√©mu napi≈° kr√°tk√© vysvƒõtlen√≠ (max 12 slov),
   - vra≈• jako slovn√≠k {{"slovo": "vysvƒõtlen√≠", ...}}.
5) Vytvo≈ô OT√ÅZKY A/B/C:
   - A: 3‚Äì4 ot√°zky na vyhled√°v√°n√≠ informac√≠ v textu (konkr√©tn√≠ odpovƒõdi).
   - B: 2‚Äì3 ot√°zky na porozumƒõn√≠ a interpretaci (vysvƒõtlen√≠ vlastn√≠mi slovy).
   - C: 2‚Äì3 ot√°zky na n√°zor / kritick√© ƒçten√≠ (≈æ√°k argumentuje).
   - Stylovƒõ podobn√© √∫loh√°m ƒå≈†I (ƒçten√≠ s porozumƒõn√≠m), v souladu s RVP ZV.

VRA≈§ POUZE JSON VE FORM√ÅTU:

{{
  "simpl": "...",
  "lmp": "...",
  "drama_intro": "...",
  "drama_scene": [
    ["Role 1", "replika 1"],
    ["Role 2", "replika 2"]
  ],
  "glossary": {{
    "slovo1": "vysvƒõtlen√≠1",
    "slovo2": "vysvƒõtlen√≠2"
  }},
  "questions_A": ["ot√°zka A1", "ot√°zka A2"],
  "questions_B": ["ot√°zka B1", "ot√°zka B2"],
  "questions_C": ["ot√°zka C1", "ot√°zka C2"]
}}
"""

    out = call_openai_chat(system, user, temperature=0.2, max_tokens=2600)
    data = json.loads(out)

    simpl = str(data.get("simpl", full_text)).strip() or full_text
    lmp = str(data.get("lmp", full_text)).strip() or full_text
    drama_intro = str(data.get("drama_intro", "")).strip()
    drama_scene_raw = data.get("drama_scene", [])
    drama_scene: List[Tuple[str, str]] = []
    for item in drama_scene_raw:
        if isinstance(item, (list, tuple)) and len(item) == 2:
            role = str(item[0]).strip()
            line = str(item[1]).strip()
            if role and line:
                drama_scene.append((role, line))

    glossary_raw = data.get("glossary", {})
    glossary: Dict[str, str] = {}
    if isinstance(glossary_raw, dict):
        for k, v in glossary_raw.items():
            kk = str(k).strip()
            vv = str(v).strip()
            if kk and vv:
                glossary[kk] = vv

    def _clean_list(key: str) -> List[str]:
        arr = data.get(key, [])
        out_list: List[str] = []
        if isinstance(arr, list):
            for q in arr:
                qq = str(q).strip()
                if qq:
                    out_list.append(qq)
        return out_list or [f"(≈Ω√°dn√© ot√°zky v sekci {key} ‚Äì zkus generovat znovu.)"]

    questions_A = _clean_list("questions_A")
    questions_B = _clean_list("questions_B")
    questions_C = _clean_list("questions_C")

    return GeneratedStructure(
        simpl=simpl,
        lmp=lmp,
        drama_intro=drama_intro or "Na zaƒç√°tku si kr√°tce zahrajeme sc√©nku, kter√° ti pom≈Ø≈æe pochopit, o ƒçem text bude.",
        drama_scene=drama_scene,
        glossary=glossary,
        questions_A=questions_A,
        questions_B=questions_B,
        questions_C=questions_C,
    )


# =========================
# DOCX ‚Äì stavba pracovn√≠ho listu
# =========================
def add_glossary_block(doc: Document, glossary: Dict[str, str]) -> None:
    add_h2(doc, "Slovn√≠ƒçek pojm≈Ø")
    if not glossary:
        doc.add_paragraph("Slovn√≠ƒçek nen√≠ k dispozici.")
        return

    doc.add_paragraph("Nejd≈ô√≠v si slov√≠ƒçka projdƒõte spoleƒçnƒõ s uƒçitelem/kou. Pak se vra≈•te k textu.")
    for w, expl in glossary.items():
        p = doc.add_paragraph()
        r = p.add_run(f"‚Ä¢ {w} ‚Äî ")
        r.bold = True
        p.add_run(expl)
        p.add_run("  | Pozn√°mka: ________________________________")


def build_student_doc(
    title: str,
    grade: int,
    variant_label: str,
    text_variant: str,
    drama_intro: str,
    drama_scene: List[Tuple[str, str]],
    glossary: Dict[str, str],
    questions_A: List[str],
    questions_B: List[str],
    questions_C: List[str],
) -> Document:
    doc = Document()
    set_doc_defaults(doc)

    add_h1(doc, f"N√ÅZEV √öLOHY: {title} ‚Äî {variant_label}")
    doc.add_paragraph(f"Roƒçn√≠k: {grade}. t≈ô√≠da")
    doc.add_paragraph("JM√âNO: ________________________________    DATUM: _______________")
    add_spacer(doc, 0.2)

    # 1) dramatizace
    add_h2(doc, "1) Kr√°tk√° dramatizace (zaƒç√°tek hodiny)")
    doc.add_paragraph(drama_intro)
    for role, line in drama_scene:
        doc.add_paragraph(f"{role}: {line}")
    add_spacer(doc, 0.2)

    # 2) text
    add_h2(doc, "2) Text pro ƒçten√≠")
    doc.add_paragraph(text_variant)
    add_spacer(doc, 0.2)

    # 3) ot√°zky
    add_h2(doc, "3) Ot√°zky k textu")

    doc.add_paragraph("A) Najdi v textu (vyhled√°v√°n√≠ informac√≠):")
    for q in questions_A:
        doc.add_paragraph(f"‚Ä¢ {q}\n  Odpovƒõƒè: ______________________________________________")

    add_spacer(doc, 0.15)
    doc.add_paragraph("B) P≈ôem√Ω≈°lej a vysvƒõtli (porozumƒõn√≠ / interpretace):")
    for q in questions_B:
        doc.add_paragraph(
            f"‚Ä¢ {q}\n  Odpovƒõƒè: ______________________________________________\n  ______________________________________________"
        )

    add_spacer(doc, 0.15)
    doc.add_paragraph("C) M≈Øj n√°zor (kritick√© ƒçten√≠ / argumentace):")
    for q in questions_C:
        doc.add_paragraph(
            f"‚Ä¢ {q}\n  Odpovƒõƒè: ______________________________________________\n  ______________________________________________"
        )

    add_spacer(doc, 0.25)
    add_glossary_block(doc, glossary)

    return doc


def build_method_doc(
    title: str,
    grade: int,
    full_text: str,
    structure: GeneratedStructure,
) -> Document:
    doc = Document()
    set_doc_defaults(doc)

    add_h1(doc, f"Metodick√Ω list pro uƒçitele ‚Äî {title}")
    doc.add_paragraph(f"Roƒçn√≠k: {grade}. t≈ô√≠da")

    add_h2(doc, "C√≠l hodiny")
    doc.add_paragraph(
        "Rozvoj ƒçten√°≈ôsk√© gramotnosti v souladu s RVP ZV: vyhled√°v√°n√≠ informac√≠, porozumƒõn√≠ textu, interpretace, "
        "kritick√© ƒçten√≠ a formulace vlastn√≠ho n√°zoru."
    )

    add_h2(doc, "Doporuƒçen√Ω postup (45 min)")
    doc.add_paragraph("1) Dramatizace (5‚Äì7 min) ‚Äì kr√°tk√° sc√©nka podle pracovn√≠ho listu, motivace a vhled do t√©matu.")
    doc.add_paragraph(
        "2) Slovn√≠ƒçek (5‚Äì8 min) ‚Äì i kdy≈æ je na konci listu, pracujte s n√≠m hned po dramatizaci. "
        "Vyberte slova, kter√° mohou brzdit porozumƒõn√≠, kr√°tce vysvƒõtlete, ≈æ√°ci si dopln√≠ pozn√°mky."
    )
    doc.add_paragraph("3) ƒåten√≠ textu (10‚Äì12 min) ‚Äì tich√© ƒçten√≠ / ƒçten√≠ po odstavc√≠ch, kontroln√≠ ot√°zky.")
    doc.add_paragraph(
        "4) Ot√°zky A/B/C (15‚Äì18 min) ‚Äì A: dohled√°n√≠ informace v textu, B: vysvƒõtlen√≠ vlastn√≠mi slovy, "
        "C: vlastn√≠ n√°zor a zd≈Øvodnƒõn√≠."
    )
    doc.add_paragraph("5) Reflexe (2‚Äì3 min) ‚Äì co ≈æ√°k≈Øm pomohlo porozumƒõt (dramatizace, slovn√≠ƒçek, ot√°zky).")

    add_h2(doc, "Pozn√°mka k verz√≠m textu")
    doc.add_paragraph("Pln√° verze: p≈Øvodn√≠ text (vstup uƒçitele).")
    doc.add_paragraph("Zjednodu≈°en√° verze: krat≈°√≠ vƒõty, jednodu≈°≈°√≠ slovn√≠ z√°soba, zachov√°n√≠ kl√≠ƒçov√Ωch informac√≠.")
    doc.add_paragraph("LMP/SPU verze: velmi kr√°tk√© vƒõty, maxim√°ln√≠ srozumitelnost, odstranƒõn√≠ slo≈æit√Ωch souvƒõt√≠.")

    add_h2(doc, "Vstupn√≠ text (pln√° verze)")
    doc.add_paragraph(full_text)

    add_h2(doc, "Zjednodu≈°en√° verze (n√°hled)")
    doc.add_paragraph(structure.simpl)

    add_h2(doc, "LMP/SPU verze (n√°hled)")
    doc.add_paragraph(structure.lmp)

    return doc


# =========================
# Generov√°n√≠ v≈°ech dokument≈Ø z vlastn√≠ho textu
# =========================
def generate_all_from_text(title: str, grade: int, full_text: str) -> Dict[str, bytes]:
    structure = ai_generate_structure(full_text, grade, title)

    doc_full = build_student_doc(
        title=title,
        grade=grade,
        variant_label="PLN√ù",
        text_variant=full_text,
        drama_intro=structure.drama_intro,
        drama_scene=structure.drama_scene,
        glossary=structure.glossary,
        questions_A=structure.questions_A,
        questions_B=structure.questions_B,
        questions_C=structure.questions_C,
    )

    doc_simpl = build_student_doc(
        title=title,
        grade=grade,
        variant_label="ZJEDNODU≈†EN√ù",
        text_variant=structure.simpl,
        drama_intro=structure.drama_intro,
        drama_scene=structure.drama_scene,
        glossary=structure.glossary,
        questions_A=structure.questions_A,
        questions_B=structure.questions_B,
        questions_C=structure.questions_C,
    )

    doc_lmp = build_student_doc(
        title=title,
        grade=grade,
        variant_label="LMP/SPU",
        text_variant=structure.lmp,
        drama_intro=structure.drama_intro,
        drama_scene=structure.drama_scene,
        glossary=structure.glossary,
        questions_A=structure.questions_A,
        questions_B=structure.questions_B,
        questions_C=structure.questions_C,
    )

    doc_method = build_method_doc(
        title=title,
        grade=grade,
        full_text=full_text,
        structure=structure,
    )

    out: Dict[str, bytes] = {
        "pl_full": doc_to_bytes(doc_full),
        "pl_simpl": doc_to_bytes(doc_simpl),
        "pl_lmp": doc_to_bytes(doc_lmp),
        "method": doc_to_bytes(doc_method),
    }
    return out


# =========================
# Streamlit state + UI
# =========================
def ensure_state():
    if "files" not in st.session_state:
        st.session_state["files"] = {}
    if "names" not in st.session_state:
        st.session_state["names"] = {}
    if "generated" not in st.session_state:
        st.session_state["generated"] = False


def show_downloads():
    files: Dict[str, bytes] = st.session_state.get("files", {})
    names: Dict[str, str] = st.session_state.get("names", {})
    if not files:
        return

    st.subheader("Sta≈æen√≠ dokument≈Ø")

    labels = {
        "pl_full": "‚¨áÔ∏è Pracovn√≠ list ‚Äì pln√° verze",
        "pl_simpl": "‚¨áÔ∏è Pracovn√≠ list ‚Äì zjednodu≈°en√° verze",
        "pl_lmp": "‚¨áÔ∏è Pracovn√≠ list ‚Äì LMP/SPU verze",
        "method": "‚¨áÔ∏è Metodick√Ω list pro uƒçitele",
    }

    order = ["pl_full", "pl_simpl", "pl_lmp", "method"]
    for k in order:
        if k in files:
            st.download_button(
                label=labels.get(k, f"St√°hnout {k}"),
                data=files[k],
                file_name=names.get(k, f"{k}.docx"),
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                key=f"dl_{k}",
            )

    if st.button("üßπ Vymazat vygenerovan√© soubory", key="clear_btn"):
        st.session_state["files"] = {}
        st.session_state["names"] = {}
        st.session_state["generated"] = False
        st.success("Vygenerovan√© soubory byly vymaz√°ny.")


def main():
    st.set_page_config(page_title="EdRead AI ‚Äì vlastn√≠ text", layout="centered")
    ensure_state()

    st.title("EdRead AI ‚Äî pracovn√≠ list z vlastn√≠ho textu")

    if get_openai_key():
        st.success(f"OPENAI_API_KEY nalezen. Model: {get_openai_model()}")
    else:
        st.warning("Chyb√≠ OPENAI_API_KEY ‚Üí v≈°e pobƒõ≈æ√≠ v nouzov√©m re≈æimu (bez AI √∫prav).")

    st.info(
        "Vlo≈æ vlastn√≠ text. EdRead AI z nƒõj vytvo≈ô√≠ pln√Ω, zjednodu≈°en√Ω a LMP/SPU pracovn√≠ list "
        "s dramatizac√≠, slovn√≠ƒçkem a ot√°zkami A/B/C ve stylu ƒå≈†I / RVP ZV."
    )

    title = st.text_input("N√°zev √∫lohy:", value="Moje ƒçten√≠ s porozumƒõn√≠m")
    grade = st.number_input("Roƒçn√≠k (1‚Äì9):", min_value=1, max_value=9, value=5, step=1)
    full_text = st.text_area("Vlo≈æ text pro ƒçten√≠:", height=300, placeholder="Sem vlo≈æ cel√Ω text, se kter√Ωm chce≈° pracovat...")

    if st.button("Vygenerovat pracovn√≠ listy", type="primary", key="btn_generate"):
        if not full_text.strip():
            st.error("Nejd≈ô√≠v vlo≈æ text.")
        else:
            try:
                with st.spinner("Generuji pracovn√≠ listy‚Ä¶"):
                    out = generate_all_from_text(title, int(grade), full_text.strip())
                st.session_state["files"] = out
                st.session_state["names"] = {
                    "pl_full": f"pracovni_list_{title}_plny.docx",
                    "pl_simpl": f"pracovni_list_{title}_zjednoduseny.docx",
                    "pl_lmp": f"pracovni_list_{title}_LMP_SPU.docx",
                    "method": f"metodika_{title}.docx",
                }
                st.session_state["generated"] = True
                st.success("Hotovo. Dokumenty jsou p≈ôipraven√© ke sta≈æen√≠.")
            except Exception as e:
                st.error(f"Do≈°lo k chybƒõ p≈ôi generov√°n√≠: {e}")

    show_downloads()


if __name__ == "__main__":
    main()
